Python — высокоуровневый язык программирования общего назначения с динамической строгой типизацией и автоматическим управлением памятью. Создан в конце 1980-х годов Гвидо ван Россумом. Python поддерживает структурное, объектно-ориентированное, функциональное, императивное и аспектно-ориентированное программирование.

Машинное обучение (Machine Learning) — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных обучаться. Машинное обучение находит применение в тех задачах, где сложно или невозможно создать алгоритм для решения напрямую, однако существует достаточное количество информации в виде примеров для построения приближенного решения.

Искусственный интеллект (ИИ, AI) — свойство интеллектуальных систем выполнять творческие функции, которые традиционно считаются прерогативой человека. В настоящее время не существует чёткого определения данного понятия. Термин "искусственный интеллект" был предложен в 1956 году на Дартмутской конференции.

Нейронная сеть — математическая модель, а также её программное или аппаратное воплощение, построенная по принципу организации и функционирования биологических нейронных сетей. Нейронные сети представляют собой систему соединённых и взаимодействующих между собой искусственных нейронов.

Векторная база данных — это специализированная система управления базами данных, оптимизированная для хранения и поиска векторных представлений данных. Векторные БД используются в задачах машинного обучения, обработки естественного языка и компьютерного зрения для быстрого поиска похожих объектов.

RAG (Retrieval-Augmented Generation) — это техника, которая комбинирует поиск информации с генерацией текста. RAG сначала ищет релевантные документы в базе знаний, а затем использует их для генерации более точных и контекстуальных ответов. Это помогает уменьшить галлюцинации языковых моделей.

Эмбеддинги (embeddings) — это векторные представления текста, где семантически похожие тексты имеют близкие векторы. Эмбеддинги создаются с помощью нейронных сетей и позволяют измерять семантическую близость между текстами, что критично для семантического поиска и RAG систем.

Трансформеры (Transformers) — это архитектура нейронных сетей, представленная в 2017 году в статье "Attention is All You Need". Трансформеры основаны на механизме внимания и стали основой современных языковых моделей, таких как GPT, BERT и других больших языковых моделей.

